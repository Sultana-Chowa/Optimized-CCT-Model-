{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class SpatialAttention(layers.Layer):\n",
        "    def __init__(self, channels, **kwargs):\n",
        "        super(SpatialAttention, self).__init__(**kwargs)\n",
        "        self.channels = channels\n",
        "        self.conv1 = layers.Conv1D(channels // 8, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "        self.conv2 = layers.Conv1D(channels // 8, kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "        self.conv3 = layers.Conv1D(channels, kernel_size=1, strides=1, padding='same', activation='sigmoid')\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(SpatialAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        avg_pool = tf.reduce_mean(x, axis=1, keepdims=True)\n",
        "        max_pool = tf.reduce_max(x, axis=1, keepdims=True)\n",
        "        x = layers.Concatenate(axis=1)([avg_pool, max_pool])\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x = tf.image.resize(x, (tf.shape(x)[1], 1))\n",
        "        return x"
      ],
      "metadata": {
        "id": "FiKO40Q8CuPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9jXX_SkCKkp"
      },
      "outputs": [],
      "source": [
        "def create_cct_model(\n",
        "    image_size=image_size,\n",
        "    input_shape=input_shape,\n",
        "    num_heads=num_heads,\n",
        "    projection_dim=projection_dim,\n",
        "    transformer_units=transformer_units,\n",
        "):\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "\n",
        "    # Encode patches.\n",
        "    cct_tokenizer = CCTTokenizer()\n",
        "    encoded_patches = cct_tokenizer(augmented)\n",
        "\n",
        "    # Apply positional embedding.\n",
        "    if positional_emb:\n",
        "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
        "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
        "        position_embeddings = pos_embed(positions)\n",
        "        encoded_patches += position_embeddings\n",
        "\n",
        "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
        "        attention_output = SpatialAttention(channels=projection_dim)(x1)\n",
        "\n",
        "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-5)(x2)\n",
        "\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "\n",
        "        x3 = StochasticDepth(dpr[i])(x3)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Apply sequence pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
        "    attention_weights = tf.nn.softmax(layers.Dense(1)(representation), axis=1)\n",
        "    weighted_representation = tf.matmul(\n",
        "        attention_weights, representation, transpose_a=True\n",
        "    )\n",
        "    weighted_representation = tf.squeeze(weighted_representation, -2)\n",
        "    logits = layers.Dense(num_classes)(weighted_representation)\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(\n",
        "            from_logits=True, label_smoothing=0.1\n",
        "        ),\n",
        "        metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/content/CCTmodel.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=128,\n",
        "        epochs=100,\n",
        "        validation_split=0.15,\n",
        "        callbacks=[checkpoint_callback]\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "    target_names = [\"CNV\", \"DME\", \"Drusen\", \"NORMAL\"]\n",
        "\n",
        "    # get predict prob and label\n",
        "    ypred = model.predict(x_test, verbose=1)\n",
        "    ypred = np.argmax(ypred, axis=1)\n",
        "    print(classification_report(np.argmax(y_test, axis=1), ypred, target_names=target_names))\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "\n",
        "    cm = confusion_matrix(np.argmax(y_test, axis=1), ypred)\n",
        "    cm = pd.DataFrame(cm, range(4),range(4))\n",
        "    plt.figure(figsize = (10,10))\n",
        "\n",
        "    sns.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "    plt.show()\n",
        "    return history\n",
        "\n",
        "\n",
        "cct_model = create_cct_model()\n",
        "history = run_experiment(cct_model)"
      ],
      "metadata": {
        "id": "BTrEBMmICwBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}